<H3>评估准则</H3>

<p>
	Bias_AUC，是一个改进版的AUC指标，用于纠正可能存在的模型偏差<br/>
	比如：数据集中很多包含'gay'的评论，在大部分情况下都是判断为具有同性恋的评论，而这更可能使得评论更具有歧视性<br/>
	但是'gay'同时也具有快乐的意思。如果模型根据统计信息将'gay'视作一个恶意评论的特征，那些'gay'表示快乐的评论<br/>
	也会被视为恶意评论，因而被删除。在实际中，误删评论的代价是很大的，很可能会引起更大的舆论。<br/>
	<br/>
	Bias_AUC是一个更完备的评价指标，目的就是纠正这种情况。<br/>
	<br/>
	AUC的计算：计算的是ROC曲线的AUC指标。<br/>
	<br/>
	Bias AUC包含4项不同的AUC，每个AUC使用测试集不同的部分进行评价，如下<br/>
	1. 全体AUC：<br/>
	所有数据上进行AUC的计算。
	2. Subgroup AUC：<br/>
	将包含一些特定词汇（'male', 'female'等)的评论选取出来，计算AUC，目的是测试模型是否能在包含这些特定词汇的情况下判断恶意评论<br/>
	<br/>
	3. BPSN (Background Positive, Subgroup Negative) AUC：<br/>
	在非恶意评论中选出带有特定词汇的评论，在恶意评论中则反之，选取不包含这些词汇的评论。<br/>
	<br/>
	4. BNSP (Background Negative, Subgroup Positive) AUC：<br/>
	与BPSN类似，但是做法相反<br/>
	<br/>
	最终的Bias_AUC通过这几项加权平均得到<br/>
	具体可以参考数据集中的评估代码<br/>

</p>